---
title: "Non-probability-based Surveys in Practice"
author: Matthew Salganik and Lai Wei ^[based on the activities from SICSS 2017 - 2020 with input from Matthew Salganik, Yo-Yo Chen, Janet Xu, Cambria Naslund, and Robin Lee).]
date: "Summer Institute in Computational Social Science 2021" 
output:
  html_document:
    df_print: paged
    toc: yes
---

```{r, echo=F}
knitr::opts_chunk$set(echo = TRUE, message = FALSE, warning = FALSE)
```

# Load packages and data

```{r, message = F, warning = F, echo = T }
# load packages
library(tidyverse)
library(lme4)
# set your working directory
# setwd("~/user/working_directory")
# load cleaned data file for survey results
data <- read_csv("https://raw.githubusercontent.com/compsocialscience/summer-institute/master/2021/materials/day4-surveys/activity/2021_clean_mturk_data.csv")
# load external information -- in this case, population info
census <- read_csv("https://raw.githubusercontent.com/compsocialscience/summer-institute/master/2021/materials/day4-surveys/activity/2019_acs_data_clean.csv")
# load pew benchmarks
pew <- read_csv("https://raw.githubusercontent.com/compsocialscience/summer-institute/master/2021/materials/day4-surveys/activity/pew_benchmark_2021.csv")

# You can find more info about the pew benchmark under "source" and "label" variable, which we will drop in the analysis.

pew <- pew %>% dplyr::select(qid, pew_estimate)

# add one variable that denotes the group the question belongs
pew[1:11,"type"] <- "media"
pew[12:30,"type"] <- "priority"

```

\newpage

# Approach 1: Simple means 

First, we'll just take the mean of the whole sample for each question. This approach doesn't use any post-stratification.

## 1.1) Calculate means

```{r}
# take the mean of survey responses in mturk data
## remove demographic variables (factor vars)
## get column means
mturk_means <- data %>% dplyr::select(-sex, -race, -age_cat, -region) %>%
  summarise_all(~mean(., na.rm = T)) %>%
## reshape from wide to long using tidyr package
## with columns for questions (call this qid) and for mean 
## having the data in long format makes it easier to merge with the pew estimate for plotting figure 1
  pivot_longer(twitter:da, names_to = "qid", 
               values_to = "mean")
# preview
head(mturk_means)
```

## 1.2) Plot estimated means against benchmarks

**Tip**: You will be making this type of plot each time you generate a new set of estimates, so it would be helpful to write a function for this.

```{r}
# merge mturk mean estimates with benchmark
mean_est <- inner_join(pew, mturk_means, by = c("qid"))
head(mean_est)
# make function for plot
plot_comparison <- function(est_table, method, caption){
  graph <-  ggplot(est_table, 
                   aes(x = pew_estimate, y = method)) + 
  geom_point(aes(color = type)) + 
  labs(x = "Estimates from Pew", y = caption) +
  scale_x_continuous(limits = c(0,1)) + 
  scale_y_continuous(limits = c(0,1)) + 
  geom_abline(intercept = 0, slope = 1, linetype = "dotted") + 
  coord_fixed()
  return(graph)
}  
# plot
plot_comparison(est_table = mean_est, 
                method = mean_est$mean, 
                caption = "Non-weighted estimates from MTurk")
```

## 1.3) Plot distribution of estimation-benchmark differences 

**Tip**: You will also be making this type of plot each time you generate a new set of estimates, so it would be helpful to write a function for this as well.

```{r}
# calculate difference
mean_est$diff <- abs(mean_est$mean - mean_est$pew_estimate)
# function for plotting difference
plot_diff <- function(est_table){
  diff_graph <- ggplot(est_table, aes(x = diff)) + 
  geom_histogram(aes(y = (..count..)/sum(..count..),fill=type), binwidth = .025, 
                 colour = "black") + 
  theme_bw() + 
  geom_vline(aes(xintercept = median(diff)), linetype = "longdash") + 
  labs(x = "absolute difference", y = "density") + 
  scale_y_continuous(limits = c(0, 0.45)) 
  return(diff_graph)
}
# plot
plot_diff(mean_est)
```

\newpage

# Approach 2: Means with post-stratification (8 groups)

## 2.1) Calculate group means, group weights, and weighted means

To start, group by sex and region only. This should give you 8 groups (2 sexes by 4 regions).

Group weights can be calculated as $\frac{N_{h}}{N}$. They should sum to 1. You will need to calculate these group weights for the other approaches as well. 

```{r}
# get total census population
N <- sum(census$POP)
# calculate group weights 
## group population data by sex and region,
## get the sum for each cell and divide by total pop
population_counts <- census %>% 
  group_by(sex, region) %>%
  summarise(group_weight = sum(POP)/N)
# check that weights sum to one
if (sum(population_counts$group_weight) != 1) {
  print("weights don't sum to one")
}
head(population_counts)
# calculate group means for each question response
## group data by sex and region
## remove non-numeric variables (demographic vars)
## calculate group means for each column
sample_counts <- data %>%
  group_by(sex, region) %>% 
  select_if(is.numeric) %>%
  summarise_all(list(~mean(.,na.rm = T)))
# preview -- scroll for more columns
head(sample_counts)
# check that there are no empty cells
if (nrow(sample_counts) < nrow(population_counts)) {
  print("GROUPS MISSING:")
  print(nrow(population_counts) - nrow(sample_counts))
}
# merge population counts with sample counts
# left join and retain all groups in population
cell_based <- left_join(population_counts, 
            sample_counts, 
            by = c("sex", "region"))
# reshape wide to long
cell_based_long <- cell_based %>% pivot_longer(twitter:da, names_to = "qid", 
               values_to = "mean")
head(cell_based_long)
# multiply the group means and group weights in the cell_based_long dataframe 
# and call this weighted_mean
cell_based_long <- mutate(cell_based_long, weighted_mean = group_weight*mean)
# sum weighted means, grouping by question
mturk_cell_est <- cell_based_long %>% 
  group_by(qid) %>%
  summarise(mturk_cell_estimate = sum(weighted_mean, na.rm = T))
```

## 2.2) Plot estimated means against benchmarks

```{r}
# merge mturk cell-based weighted estimates with benchmark
simple_cell_est <- inner_join(pew, mturk_cell_est, by = c("qid"))
head(simple_cell_est)
# plot (you can use the function we created above)
plot_comparison(est_table = simple_cell_est, 
                method = simple_cell_est$mturk_cell_estimate, 
                caption = "Simple cell-based adjusted estimates from MTurk")
```

## 2.3) Plot distribution of estimation-benchmark differences

```{r}
#calculate difference
simple_cell_est$diff <- abs(simple_cell_est$pew_estimate - simple_cell_est$mturk_cell_estimate)
#plot
plot_diff(simple_cell_est)
```


\newpage

# Approach 3: Means with post-stratification (160 groups) and missing group imputation

## 3.1) Calculate group means, group weights, and weighted means

Can you get better estimates grouping by more variables? Try grouping on sex, region, age group, and race. 

You will now have 160 groups (2 x 4 x 5 x 4). Some of groups may be missing from your sample (e.g. 50-64 year old black women in the midwest). If a group is missing, their answers will automatically be treated as "zero" when computing weighted means. As a result, some question responses may be underestimated. One way to deal with this is to impute the missing values with the sample average for that variable (aka the simple means we calculated in the first step). You will do this in the next step. 

First, calculate the new group means, group weights, and weighted means as you did above in Approach 2. We provide hints in comments to help you analze the data. 

```{r}
## Step 1: group population data by sex and region, age group and race
## To get group weight, get the sum for each cell and divide by total pop
population_counts <- census %>% 
  group_by(sex, region, age_cat, race) %>% 
  summarise(group_weight = sum(POP)/N)
## Step 2: check that weights sum to one
if (sum(population_counts$group_weight) != 1) {
  print("weights don't sum to one")
}
## Step 3: calculate group means for each question response
sample_counts <- data  %>%
  group_by(sex, region, age_cat, race) %>%
  summarise_all(list(~mean(.,na.rm = T)))
## Step 4: check how many empty cells there are
if (nrow(sample_counts) < nrow(population_counts)) {
  print("GROUPS MISSING:")
  print(nrow(population_counts) - nrow(sample_counts))
}
## Step 5: append group weights obtained from step 1 
cell_based <- left_join(population_counts, 
            sample_counts, 
            by = c("sex", "region", "age_cat", "race")) 
cell_based_long <- cell_based %>% 
  pivot_longer(twitter:da, names_to = "qid", 
               values_to = "mean") %>%
  mutate(weighted_mean = group_weight*mean)
# Step 6: sum the group-specific weighted means, grouping by question
mturk_cell_est <- cell_based_long %>% 
  group_by(qid) %>%
  summarise(mturk_cell_estimate = sum(weighted_mean, na.rm = T))
```

### 3.1.1) Dealing with missing groups: imputing with sample means

Now, replace the missing groups with the sample means you computed in 1.1. 

```{r}
# replace missing group means with sample means
missing_groups <- cell_based_long %>% filter(is.na(mean))
missing_groups_imputed <- inner_join(missing_groups, mturk_means, by = c("qid")) %>%
  dplyr::select(-mean.x, -weighted_mean) %>%
  rename(mean = mean.y)
# now merge back with all non-missing groups (stored in cell_based_long)
cell_based_long_imputed <- right_join(missing_groups_imputed, cell_based_long,
                                     by = c("sex", "age_cat", "region", "race",
                                            "group_weight" , "qid")) %>%
                            mutate(mean = ifelse(is.na(mean.x), mean.y, mean.x)) %>%
                            dplyr::select(-mean.x, -mean.y, -weighted_mean) %>%
# and recalculate weighted means  
                            mutate(weighted_mean_imputed = group_weight*mean)
# then sum the group-specific weighted means, grouping by question
cell_est_imputed <- cell_based_long_imputed %>% 
  group_by(qid) %>%
  summarise(mturk_cell_estimate = sum(weighted_mean_imputed, na.rm = T))
```

## 3.2) Plot estimated means against benchmarks

Plot both your new group means and the estimated means against the Pew benchmarks. 

```{r}
################################## WITH NO IMPUTATION ###################################
## Step 1: append benchmark estimate
cell_based_est <- inner_join(pew, mturk_cell_est, by = c("qid"))
## Step 2: generate the comparison graph from the first function we made
plot_comparison(est_table = cell_based_est, 
                method = cell_based_est$mturk_cell_estimate, 
                caption = "Cell-based weighted estimates from MTurk")
################################## WITH IMPUTATION ######################################
## Step 1: append benchmark estimate
cell_est_imputed <- inner_join(pew, cell_est_imputed, by = c("qid"))
## Step 2: generate the comparison graph from the first function we made
plot_comparison(est_table = cell_est_imputed, 
                method = cell_est_imputed$mturk_cell_estimate, 
                caption = "Cell-based weighted estimates from MTurk (with data imputation)")
```


## 3.3) Plot distribution of estimation-benchmark differences

```{r}
#################################### WITH NO IMPUTATION #################################
cell_based_est$diff <- abs(cell_based_est$pew_estimate - cell_based_est$mturk_cell_estimate)
plot_diff(cell_based_est)
#################################### IMPUTATION #######################################
cell_est_imputed$diff <- abs(cell_est_imputed$pew_estimate - cell_est_imputed$mturk_cell_estimate)
plot_diff(cell_est_imputed)
```

\newpage
# Approach 4: Model-based estimation with post-stratification

## 4.1) Predict group means with simple regression model; combine with group weights to create weighted means

```{r}
# for this, we will need convert everything into factors
data_factor <- data
for (col in colnames(data_factor)) {
  data_factor[,col] <- factor(pull(data_factor,col))
}


# Now we will regress each survey answer on demographic characteristics and
# use those model parameters to generate predicted probabilities for each group
# loop through each survey answer and store each vector of pred.probs
# in a 160 x 30 matrix 
# but first, write a warning function for later to make sure 
# that all estimates are 0 to 1 inclusive
prob_range_warning <- function(predictions){
  if (any(predictions < 0)) {
    warning("some predictions less than zero")
    } 
  if (any(predictions > 1)) {
    warning("some predictions more than one")
    } 
}
# create a character vector of the 30 question names
# these question names can be found in the column names of the data
relevant_questions <- colnames(data)[!colnames(data) %in% c("sex", "age_cat", "region", "race")]
# create container
model_predictions <- as.data.frame(matrix(nrow = nrow(population_counts), 
                                          ncol = length(relevant_questions), NA))
colnames(model_predictions) <- relevant_questions
# loop through
for (i in relevant_questions) {
  # get outcome
  outcome <- data_factor[ , i] %>% as.vector()
  # fit model
  temp_df <- data_factor %>% dplyr::select(sex, age_cat, region, race) %>%
    cbind(outcome)
  colnames(temp_df) <- c("sex","age_cat","region","race","outcome")
  model <- glm(outcome ~ sex + age_cat + region + race, 
             data = temp_df,
             family = binomial(link = "logit"))
  # create predicted probabilities
  reg_predicted_values <- predict(model, newdata = population_counts, type = "response")
  # check for errors
  prob_range_warning(reg_predicted_values)
  # store in container
  model_predictions[ , i] <- reg_predicted_values
}
# bind demographic categories to predictions
model_wide <- bind_cols(population_counts, model_predictions)
head(model_wide)
# reshape wide to long
model_long <- model_wide %>% gather(qid, predicted_value, 
                                         -c(sex, age_cat, region, race, group_weight),
                                         na.rm = F) 
head(model_long)
# weight predictions and sum by qid
model_est <- model_long %>%
  mutate(weighted_prediction = group_weight*predicted_value) %>%
  group_by(qid) %>%
  summarise(model_prediction = sum(weighted_prediction, na.rm = T)) 
head(model_est)
# merge with pew benchmarks
pew_model_est <- inner_join(pew, model_est, by = c("qid"))
```

## 4.2) Plot estimated means against benchmarks

```{r}
plot_comparison(est_table = pew_model_est,
                method = pew_model_est$model_prediction,
                caption = "Model-based predicted values") 
```

## 4.3) Plot distribution of estimation-benchmark differences 

```{r}
#calculate difference
pew_model_est$diff <- abs(pew_model_est$model_prediction - pew_model_est$pew_estimate)
#plot
plot_diff(pew_model_est)
```


\newpage

# Compare distribution of differences across methods and questions

Which questions worked well and which didn't? Which methods worked well for which questions?

```{r}
# put all differences into one table 
all_diff <- inner_join(mean_est, simple_cell_est, by = "qid") %>%
           dplyr::select(qid, diff_mean = diff.x, diff_simple_cell = diff.y) %>%
              inner_join(., cell_based_est, by = "qid") %>%
              dplyr::select(qid, diff_mean, diff_simple_cell, diff_cell = diff) %>%
              inner_join(., cell_est_imputed, by = "qid") %>%
              dplyr::select(qid, diff_mean, diff_simple_cell, diff_cell, diff_cell_imputed = diff) %>%
                  inner_join(., pew_model_est, by = "qid") %>%
                  dplyr::select(qid, diff_mean, diff_simple_cell, diff_cell, diff_cell_imputed, diff_model = diff)
# summarize
summary(all_diff, digits = 2)
# calculate MSE 
colMeans(apply(all_diff[ ,-1], 2, FUN = function(x){x^2}))
# calculate average difference across all methods for each question
all_diff$avg_diff <- apply(all_diff[ ,-1], 1, FUN = mean)
all_diff[,c("qid", "avg_diff")]

inner_join(all_diff,pew,by="qid") %>% group_by(type) %>% summarise(avg_diff = mean(avg_diff))
```

\newpage

# Optional Extension: \
  Approach 5: Multilevel-Model-based estimation with post-stratification (MRP)

### 5.1) Predict group means with multi-level regression model; combine with group weights to create weighted means

```{r}
## Note that given the small sample size and small effect of demographic variables, it is very likely that the random effects have convergence issues. Still, we keep the codes for demonstration purposes. In real research settings where these warnings occur, you should either collect more samples or tune the models.

## Students are welcome to tune the mixed effects model to remove the convergence warnings should they encounter it. The ways include switch variables from random effect to fixed effect if the estimated random effect has small variance, and change the estimation algorithm.



## if using Bayesian estimation for multi-level model, you will need to load rstanarm
## note that Bayesian estimation is more computationally intensive/takes longer
# library(rstanarm)  
# create container
outcome_outputs <- vector("list",30)
mrp_model_predictions <- as.data.frame(matrix(nrow = nrow(population_counts), 
                                          ncol = length(relevant_questions), NA))
colnames(mrp_model_predictions) <- relevant_questions
# loop through model fitting and prediction
for (i in relevant_questions) {
  outcome <- data_factor[ , i] 
  colnames(outcome) <- "outcome"
  temp_df <- data %>% dplyr::select(sex, age_cat, race, region) %>%
    cbind(outcome)
  # fit -- note that this is using default priors
  # nested the model name in "capture.out" to silently fit
  output <- capture.output(multilevel_model <-
                          glmer(outcome ~ sex + (1|age_cat) + (1|race) +
                          (1|region), data = temp_df, family = binomial(link = "logit")))
  # predict
  mrp_predictions <- predict(multilevel_model,
                                       newdata = population_counts, type = "response")
  # errors?
  prob_range_warning(mrp_predictions)
  # feed into dataframe
  mrp_model_predictions[ , i] <- mrp_predictions
  
  outcome_outputs[[i]] <- output
}
##################### Bayesian version with STAN #################################################
# library(rstanarm)
# 
# for (i in relevant_questions[1:2]) {
# outcome <- data_factor[ , i]
# # fit -- note that this is using default priors
# # nested the model name in "capture.out" to silently fit
# output <- capture.output(multilevel_model <- stan_glmer(outcome ~ sex + (1|age_cat) + (1|race) +
# (1|region), data = data, family = binomial(link = "logit"), adapt_delta = 0.99))
# # predict
# mrp_predictions <- posterior_linpred(multilevel_model,
# newdata = population_counts, type = "response")
# mrp_predictions_invlog <- exp(mrp_predictions)/(1 + exp(mrp_predictions))
# mrp_pred2 <- unname(apply(mrp_predictions_invlog, 2, mean))
# # errors?
# prob_range_warning(mrp_pred2)
# # feed into dataframe
# mrp_model_predictions[ , i] <- mrp_pred2
# }
# bind to demographic categories and group weights
mrp_wide <- bind_cols(population_counts, mrp_model_predictions)
head(mrp_wide)
# reshape wide to long
mrp_long <- mrp_wide %>% gather(qid, predicted_value, 
                                         -c(sex, age_cat, region, race, group_weight),
                                         na.rm = F) 
head(mrp_long)
# weigh, sum by qid, match with pew
mrp_est <- mrp_long %>%
  mutate(mrp_weighted_prediction = group_weight*predicted_value) %>%
  group_by(qid) %>%
  summarise(mrp_prediction = sum(mrp_weighted_prediction, na.rm = T)) 
head(mrp_est)
# merge with pew benchmarks
pew_mrp_est <- inner_join(pew, mrp_est, by = c("qid"))
```

### 5.2) Plot estimated means against benchmarks

```{r}
plot_comparison(est_table = pew_mrp_est,
                method = pew_mrp_est$mrp_prediction,
                caption = "MRP predicted values")
```

### 5.3) Plot distribution of estimation-benchmark differences

```{r}
#calculate difference
pew_mrp_est$diff <- abs(pew_mrp_est$mrp_prediction - pew_mrp_est$pew_estimate)
#plot
plot_diff(pew_mrp_est)
```

### 5.4) Compare differences from MRP with other methods

```{r}
# add mrp to table of differences
all_diff <- inner_join(all_diff, pew_mrp_est, by = "qid") %>%
                    select(qid, diff_mean, diff_simple_cell, diff_cell, diff_cell_imputed, diff_model, diff_mrp = diff)
# summarize
summary(all_diff, digits = 2)
# calculate MSE 
colMeans(apply(all_diff[ ,-1], 2, FUN = function(x){x^2}))
